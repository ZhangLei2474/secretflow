{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c0c61b-3f26-4e33-a3cb-26b168c6e212",
   "metadata": {},
   "source": [
    "# PrivateFL Implementation in SecretFlow\n",
    "\n",
    "This notebook implements the PrivateFL method based on the paper [PRIVATEFL: Accurate, Differentially Private Federated Learningvia Personalized Data Transformation]\n",
    "by [Yuchen Yang∗, Bo Hui∗, Haolin Yuan∗, Neil Gong†, and Yinzhi Cao The Johns Hopkins University, †Duke University] ([https://www.usenix.org/system/files/sec23fall-prepub-427-yang-yuchen.pdf]).\n",
    "\n",
    "The implementation has been modified and adapted to work with the SecretFlow framework\n",
    "for demonstration and educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2fa499-5f1f-473c-bec6-f6cdaa24e458",
   "metadata": {},
   "source": [
    "# PrivateFL: 基于个性化数据转换的精确差分隐私联邦学习\n",
    "\n",
    "PrivateFL是一种新的差分隐私联邦学习方法，旨在通过个性化数据转换来提高模型精度。其核心思想包括：\n",
    "\n",
    "1. 观察到差分隐私（DP）会在联邦学习中引入额外的客户端异质性，从而降低模型精度。\n",
    "2. 为每个客户端学习一个差分隐私的个性化数据转换，以减少DP引入的异质性。\n",
    "3. 数据转换与本地模型同时学习，优化以最小化学习损失并最大化本地客户端模型效用。\n",
    "4. 可与现有的个性化联邦学习方法和DP效用改进方法结合，进一步提高精度。\n",
    "\n",
    "本实现基于SecretFlow框架，展示了PrivateFL在中央差分隐私（CDP）和本地差分隐私（LDP）设置下的应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052473c-7b20-493b-bc98-a817e662d29d",
   "metadata": {},
   "source": [
    "## 1.modelUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e80cb2e-0bad-449a-add6-8183e66c36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import alexnet, resnet18\n",
    "from torch.nn.functional import relu, softmax, max_pool2d\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch import nn, tanh\n",
    "import copy\n",
    "from opacus.grad_sample import register_grad_sampler\n",
    "from typing import Dict\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "from numpy import median\n",
    "import numpy as np\n",
    "import torch.nn.functional as func\n",
    "# from secretflow.device import SPU, PYU\n",
    "\n",
    "def agg_weights(weights):\n",
    "    with torch.no_grad():\n",
    "        weights_avg = copy.deepcopy(weights[0])\n",
    "        for k in weights_avg.keys():\n",
    "            for i in range(1, len(weights)):\n",
    "                weights_avg[k] += weights[i][k]\n",
    "            weights_avg[k] = torch.div(weights_avg[k], len(weights))\n",
    "    return weights_avg\n",
    "\n",
    "def evaluate_global(users, test_dataloders, users_index):\n",
    "    # testing_corrects = 0\n",
    "    # testing_sum = 0\n",
    "    # for index in users_index:\n",
    "    #     corrects, num = users[index].evaluate(test_dataloders[index])\n",
    "    #     testing_corrects += corrects\n",
    "    #     testing_sum += num\n",
    "    # print(f\"Acc: {testing_corrects / testing_sum}\")\n",
    "    # return (testing_corrects / testing_sum)\n",
    "\n",
    "    testing_corrects = 0\n",
    "    testing_sum = 0\n",
    "    for index in users_index:\n",
    "        result = users[index].evaluate(test_dataloders[index])\n",
    "        corrects, total = sf.reveal(result)\n",
    "        testing_corrects += corrects\n",
    "        testing_sum += total\n",
    "    # 计算并返回全局准确率\n",
    "    if testing_sum > 0:\n",
    "        acc = testing_corrects / testing_sum\n",
    "        print(f\"全局准确率: {acc:.4f}\")\n",
    "        return acc\n",
    "    else:\n",
    "        print(\"没有评估任何样本\")\n",
    "        return 0\n",
    "    \n",
    "# 个性化数据转换类\n",
    "class InputNorm(nn.Module):\n",
    "    def __init__(self, num_channel, num_feature):\n",
    "        super().__init__()\n",
    "        self.num_channel = num_channel\n",
    "        self.gamma = nn.Parameter(torch.ones(num_channel))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_channel, num_feature, num_feature))\n",
    "    def forward(self, x):\n",
    "        if self.num_channel == 1:\n",
    "            x = self.gamma*x\n",
    "            x = x + self.beta\n",
    "            return  x  \n",
    "        if self.num_channel == 3:\n",
    "            return torch.einsum('...ijk, i->...ijk', x, self.gamma) + self.beta\n",
    "        \n",
    "class resnet18(torch.nn.Module):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.resnet18(pretrained=True)\n",
    "        n_ftrs = self.backbone.fc.in_features\n",
    "        self.backbone.fc = torch.nn.Linear(n_ftrs, num_classes)\n",
    "    def forward(self, x):\n",
    "        logits = self.backbone(x)\n",
    "        return logits, softmax(logits, dim=-1)\n",
    "\n",
    "class resnet18_IN(torch.nn.Module):\n",
    "    \"\"\"Constructs a ResNet-18wIN model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.resnet18(pretrained=True)\n",
    "        n_ftrs = self.backbone.fc.in_features\n",
    "        self.backbone.fc = torch.nn.Linear(n_ftrs, num_classes)\n",
    "        if num_classes == 8:\n",
    "            self.norm = InputNorm(3, 150)\n",
    "        else:\n",
    "            self.norm = InputNorm(3, 120)\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        logits = self.backbone(x)\n",
    "        return logits, softmax(logits, dim=-1)\n",
    "\n",
    "class alexnet(torch.nn.Module):\n",
    "    \"\"\"Constructs a alexnet model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.alexnet(pretrained=True)\n",
    "        n_ftrs = self.backbone.classifier[-1].out_features\n",
    "        self.fc = torch.nn.Linear(n_ftrs, num_classes)\n",
    "    def forward(self, x):\n",
    "        logits = self.backbone(x)\n",
    "        logits = self.fc(logits)\n",
    "        return logits, softmax(logits, dim=-1)\n",
    "\n",
    "\n",
    "class alexnet_IN(torch.nn.Module):\n",
    "    \"\"\"Constructs a alexnet w IN model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = torchvision.models.alexnet(pretrained=True)\n",
    "        n_ftrs = self.backbone.classifier[-1].out_features\n",
    "        self.fc = torch.nn.Linear(n_ftrs, num_classes)\n",
    "        self.norm = InputNorm(3, 150)\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        logits = self.backbone(x)\n",
    "        logits = self.fc(logits)\n",
    "        return logits, softmax(logits, dim=-1)\n",
    "\n",
    "\n",
    "class mnist_fully_connected_IN(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(mnist_fully_connected_IN, self).__init__()\n",
    "        self.hidden1 = 600\n",
    "        self.hidden2 = 100\n",
    "        self.fc1 = nn.Linear(28 * 28, self.hidden1, bias=False)\n",
    "        self.fc2 = nn.Linear(self.hidden1, self.hidden2, bias=False)\n",
    "        self.fc3 = nn.Linear(self.hidden2, num_classes, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.norm = InputNorm(1, 28)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.norm(x)\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        return logits, softmax(logits,dim=1)\n",
    "\n",
    "class mnist_fully_connected(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(mnist_fully_connected, self).__init__()\n",
    "        self.hidden1 = 600\n",
    "        self.hidden2 = 100\n",
    "        self.fc1 = nn.Linear(28 * 28, self.hidden1, bias=False)\n",
    "        self.fc2 = nn.Linear(self.hidden1, self.hidden2, bias=False)\n",
    "        self.fc3 = nn.Linear(self.hidden2, num_classes, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = relu(self.fc1(x))\n",
    "        x = relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        return logits, softmax(logits,dim=1)\n",
    "\n",
    "class purchase_fully_connected(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(purchase_fully_connected, self).__init__()\n",
    "        self.fc1 = nn.Linear(600, 512,bias=False)\n",
    "        self.fc2 = nn.Linear(512, 256,bias=False)\n",
    "        self.fc3 = nn.Linear(256, 128,bias=False)\n",
    "        self.fc4 = nn.Linear(128, num_classes,bias=False)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = tanh(self.fc1(x))\n",
    "        x = tanh(self.fc2(x))\n",
    "        x = tanh(self.fc3(x))\n",
    "        logits = self.fc4(x)\n",
    "        return logits, softmax(logits,dim=1)\n",
    "\n",
    "class purchase_fully_connected_IN(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(purchase_fully_connected_IN, self).__init__()\n",
    "        self.fc1 = nn.Linear(600,512, bias=False)\n",
    "        self.fc2 = nn.Linear(512, 256, bias=False)\n",
    "        self.fc3 = nn.Linear(256, 128, bias=False)\n",
    "        self.fc4 = nn.Linear(128, num_classes, bias=False)\n",
    "        self.norm = FeatureNorm(600)\n",
    "    def forward(self,x):\n",
    "        x = self.norm(x)\n",
    "        x = tanh(self.fc1(x))\n",
    "        x = tanh(self.fc2(x))\n",
    "        x = tanh(self.fc3(x))\n",
    "        logits = self.fc4(x)\n",
    "        return logits, softmax(logits,dim=1)\n",
    "\n",
    "class linear_model(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape=512):\n",
    "        super(linear_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, num_classes, bias=True)\n",
    "    def forward(self,x):\n",
    "        logits = self.fc1(x)\n",
    "        return logits, softmax(logits,dim=1)\n",
    "\n",
    "\n",
    "def standardize(x, bn_stats):\n",
    "    if bn_stats is None:\n",
    "        return x\n",
    "\n",
    "    bn_mean, bn_var = bn_stats\n",
    "    bn_mean, bn_var = bn_mean.to(x.device), bn_var.to(x.device)\n",
    "    view = [1] * len(x.shape)\n",
    "    view[1] = -1\n",
    "    x = (x - bn_mean.reshape(view)) / torch.sqrt(bn_var.reshape(view) + 1e-5)\n",
    "\n",
    "    # if variance is too low, just ignore\n",
    "    x *= (bn_var.reshape(view) != 0)\n",
    "    return x\n",
    "\n",
    "class linear_model_DN(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape=512, bn_stats=False):\n",
    "        super(linear_model_DN, self).__init__()\n",
    "        if not bn_stats:\n",
    "            self.bn_stats = (torch.zeros(input_shape), torch.ones(input_shape))\n",
    "        else:\n",
    "            mean = np.load('transfer/cifar100_resnext_mean.npy')\n",
    "            var = np.load('transfer/cifar100_resnext_var.npy')\n",
    "            self.bn_stats = (torch.from_numpy(mean), torch.from_numpy(var))\n",
    "        self.fc1 = nn.Linear(input_shape, num_classes, bias=True)\n",
    "    def forward(self,x):\n",
    "        x = standardize(x, self.bn_stats)\n",
    "        logits = self.fc1(x)\n",
    "        return logits, softmax(logits,dim=1)\n",
    "\n",
    "\n",
    "class FeatureNorm(nn.Module):\n",
    "    def __init__(self, feature_shape):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, feature_shape))\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.einsum('ni, j->ni', x, self.gamma) \n",
    "        x = x + self.beta\n",
    "        return  x\n",
    "\n",
    "\n",
    "@register_grad_sampler(FeatureNorm)\n",
    "def compute_grad_sample(\n",
    "    layer: InputNorm, activations: torch.Tensor, backprops: torch.Tensor\n",
    ") -> Dict[nn.Parameter, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Computes per sample gradients for ``nn.Linear`` layer\n",
    "    Args:\n",
    "        layer: Layer\n",
    "        activations: Activations\n",
    "        backprops: Backpropagations\n",
    "    \"\"\"\n",
    "    gs = torch.einsum(\"nk,nk->n\", backprops, activations)\n",
    "    ret = {layer.gamma: gs}\n",
    "    if layer.beta is not None:\n",
    "        ret[layer.beta] = torch.einsum(\"n...i->ni\", backprops)\n",
    "\n",
    "    return ret\n",
    "\n",
    "class linear_model_DN_IN(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape, bn_stats=False):\n",
    "        super(linear_model_DN_IN, self).__init__()\n",
    "        if not bn_stats:\n",
    "            self.bn_stats = (torch.zeros(input_shape), torch.ones(input_shape))\n",
    "        else:\n",
    "            mean = np.load('cifar100_resnext_mean.npy')\n",
    "            var = np.load('cifar100_resnext_mean.npy')\n",
    "            self.bn_stats = (torch.from_numpy(mean), torch.from_numpy(var))\n",
    "        self.backbone = nn.Linear(input_shape, num_classes, bias=True)\n",
    "        self.norm = FeatureNorm(input_shape)\n",
    "    def forward(self,x):\n",
    "        x = self.norm(x)\n",
    "        x = standardize(x, self.bn_stats)\n",
    "        logits = self.backbone(x)\n",
    "        return logits, softmax(logits,dim=1)\n",
    "\n",
    "@register_grad_sampler(InputNorm)\n",
    "def compute_grad_sample(\n",
    "    layer: InputNorm, activations: torch.Tensor, backprops: torch.Tensor\n",
    ") -> Dict[nn.Parameter, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Computes per sample gradients for ``nn.Linear`` layer\n",
    "    Args:\n",
    "        layer: Layer\n",
    "        activations: Activations\n",
    "        backprops: Backpropagations\n",
    "    \"\"\"\n",
    "    gs = torch.einsum(\"nk...,nk...->nk\", backprops, activations)\n",
    "    ret = {layer.gamma: gs}\n",
    "    if layer.beta is not None:\n",
    "        ret[layer.beta] = torch.einsum(\"nijk->nijk\", backprops)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda7e25-8988-4690-854b-13f3376ac3a7",
   "metadata": {},
   "source": [
    "## 2.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa5b7ff-8ee6-4fd5-837a-145becd06d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class CHMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, root ='data/CHMNIST',train=True, download=True, transform = None):\n",
    "        self.images = []\n",
    "        self.root = root\n",
    "        self.targets = []\n",
    "        self.train = train\n",
    "        self.download = download\n",
    "        self.transform = transform\n",
    "\n",
    "        x_train, x_test, y_train, y_test = self._train_test_split()\n",
    "\n",
    "        if self.train:\n",
    "            self._setup_dataset(x_train, y_train)\n",
    "        else:\n",
    "            self._setup_dataset(x_test, y_test)\n",
    "\n",
    "    def _train_test_split(self):\n",
    "        img_names = []\n",
    "        img_label = []\n",
    "        for i, folder_name in enumerate(os.listdir(self.root)):\n",
    "\n",
    "            for j, img_name in enumerate(os.listdir(self.root + '/' +folder_name)):\n",
    "                img_names.append(os.path.join(self.root+'/', folder_name, img_name))\n",
    "                img_label.append(int(folder_name[0:2])-1)\n",
    "\n",
    "        x_train,x_test, y_train, y_test = train_test_split(img_names, img_label, train_size=0.9,\n",
    "                                                            random_state=1)\n",
    "\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "    def _setup_dataset(self, x, y):\n",
    "            self.images = x\n",
    "            self.targets = y\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_fn = self.images[item]\n",
    "        label = self.targets[item]\n",
    "        img = Image.open(img_fn)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "class Purchase(torch.utils.data.Dataset):\n",
    "    def __init__(self, root ='data/purchase/dataset_purchase',train=True, download=True, transform = None):\n",
    "        self.images = []\n",
    "        self.root = root\n",
    "        self.targets = []\n",
    "        self.train = train\n",
    "        self.download = download\n",
    "        self.transform = transform\n",
    "\n",
    "        x_train, x_test, y_train, y_test = self._train_test_split()\n",
    "\n",
    "        if self.train:\n",
    "            self._setup_dataset(x_train, y_train)\n",
    "        else:\n",
    "            self._setup_dataset(x_test, y_test)\n",
    "\n",
    "    def _train_test_split(self):\n",
    "        df = pd.read_csv(self.root)\n",
    "\n",
    "        img_names = df.iloc[:, 1:].to_numpy(dtype='f')\n",
    "        img_label = df.iloc[:, 0].to_numpy()-1\n",
    "        x_train,x_test, y_train, y_test = train_test_split(img_names, img_label, train_size=0.8,\n",
    "                                                            random_state=1)\n",
    "\n",
    "\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "    def _setup_dataset(self, x, y):\n",
    "            self.images = x\n",
    "            self.targets = y\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = self.images[item]\n",
    "        label = self.targets[item]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b6cac-e3ec-4820-b178-24a3fc2a30c5",
   "metadata": {},
   "source": [
    "## 3.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06f1a5d-1cc7-4c38-8d24-451815105734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST, CIFAR100, EMNIST\n",
    "np.random.seed(2022)\n",
    "\n",
    "def get_datasets(data_name, dataroot, preprocess = None):\n",
    "    \"\"\"\n",
    "    get_datasets returns train/val/test data splits of CIFAR10/100 datasets\n",
    "    :param data_name: name of dataset, choose from [cifar10, cifar100]\n",
    "    :param dataroot: root to data dir\n",
    "    :param normalize: True/False to normalize the data\n",
    "    :param val_size: validation split size (in #samples)\n",
    "    :return: train_set, val_set, test_set (tuple of pytorch dataset/subset)\n",
    "    \"\"\"\n",
    "\n",
    "    if data_name =='cifar10':\n",
    "        normalization = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(120), normalization]) if preprocess==None else preprocess\n",
    "\n",
    "        data_obj = CIFAR10\n",
    "    elif data_name =='cifar100':\n",
    "        normalization = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(224), normalization]) if preprocess==None else preprocess\n",
    "\n",
    "        data_obj = CIFAR100\n",
    "    elif data_name == 'mnist':\n",
    "        normalization = transforms.Normalize((0.5,), (0.5,))\n",
    "        transform = transforms.Compose([transforms.ToTensor(), normalization])\n",
    "        data_obj = MNIST\n",
    "    elif data_name == 'fashionmnist':\n",
    "        normalization = transforms.Normalize((0.5,), (0.5,))\n",
    "        transform = transforms.Compose([transforms.ToTensor(),  normalization])\n",
    "        data_obj = FashionMNIST\n",
    "    elif data_name == 'emnist':\n",
    "        normalization = transforms.Normalize((0.5,), (0.5,))\n",
    "        transform = transforms.Compose([transforms.ToTensor(),  normalization])\n",
    "        data_obj = EMNIST\n",
    "    elif data_name == 'purchase':\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        data_obj = Purchase\n",
    "    elif data_name == 'chmnist':\n",
    "        normalization = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((150,150)),normalization])\n",
    "        data_obj = CHMNIST\n",
    "    else:\n",
    "        raise ValueError(\"choose data_name from ['mnist', 'cifar10', 'cifar100', 'fashionmnist', 'emnist, 'purchase', 'chmnist']\")\n",
    "\n",
    "\n",
    "    if data_name == 'emnist':\n",
    "        train_set = data_obj(\n",
    "            dataroot,\n",
    "            train=True,\n",
    "            transform=transform,\n",
    "            split='digits',\n",
    "            download=True\n",
    "        )\n",
    "\n",
    "        test_set = data_obj(\n",
    "            dataroot,\n",
    "            train=False,\n",
    "            split='digits',\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        train_set = data_obj(\n",
    "            dataroot,\n",
    "            train=True,\n",
    "            transform=transform,\n",
    "            download=True\n",
    "        )\n",
    "\n",
    "        test_set = data_obj(\n",
    "            dataroot,\n",
    "            train=False,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "def get_num_classes_samples(dataset):\n",
    "    \"\"\"\n",
    "    extracts info about certain dataset\n",
    "    :param dataset: pytorch dataset object\n",
    "    :return: dataset info number of classes, number of samples, list of labels\n",
    "    \"\"\"\n",
    "    # ---------------#\n",
    "    # Extract labels #\n",
    "    # ---------------#\n",
    "    if isinstance(dataset, torch.utils.data.Subset):\n",
    "        if isinstance(dataset.dataset.targets, list):\n",
    "            data_labels_list = np.array(dataset.dataset.targets)[dataset.indices]\n",
    "        else:\n",
    "            data_labels_list = dataset.dataset.targets[dataset.indices]\n",
    "    else:\n",
    "        if isinstance(dataset.targets, list):\n",
    "            data_labels_list = np.array(dataset.targets)\n",
    "        else:\n",
    "            data_labels_list = dataset.targets\n",
    "    classes, num_samples = np.unique(data_labels_list, return_counts=True)\n",
    "    num_classes = len(classes)\n",
    "    return num_classes, num_samples, data_labels_list\n",
    "\n",
    "\n",
    "def gen_classes_per_node(dataset, num_users, classes_per_user=2, high_prob=0.6, low_prob=0.4):\n",
    "    \"\"\"\n",
    "    creates the data distribution of each client\n",
    "    :param dataset: pytorch dataset object\n",
    "    :param num_users: number of clients\n",
    "    :param classes_per_user: number of classes assigned to each client\n",
    "    :param high_prob: highest prob sampled\n",
    "    :param low_prob: lowest prob sampled\n",
    "    :return: dictionary mapping between classes and proportions, each entry refers to other client\n",
    "    \"\"\"\n",
    "    num_classes, num_samples, _ = get_num_classes_samples(dataset)\n",
    "\n",
    "    # -------------------------------------------#\n",
    "    # Divide classes + num samples for each user #\n",
    "    # -------------------------------------------#\n",
    "    # print(num_classes)\n",
    "    assert (classes_per_user * num_users) % num_classes == 0, \"equal classes appearance is needed\"\n",
    "    count_per_class = (classes_per_user * num_users) // num_classes\n",
    "    class_dict = {}\n",
    "    for i in range(num_classes):\n",
    "        probs=np.array([1]*count_per_class)\n",
    "        probs_norm = (probs / probs.sum()).tolist()\n",
    "        class_dict[i] = {'count': count_per_class, 'prob': probs_norm}\n",
    "    # -------------------------------------#\n",
    "    # Assign each client with data indexes #\n",
    "    # -------------------------------------#\n",
    "    class_partitions = defaultdict(list)\n",
    "    for i in range(num_users):\n",
    "        c = []\n",
    "        for _ in range(classes_per_user):\n",
    "            class_counts = [class_dict[i]['count'] for i in range(num_classes)]\n",
    "            max_class_counts = np.where(np.array(class_counts) == max(class_counts))[0]\n",
    "            max_class_counts = np.setdiff1d(max_class_counts, np.array(c))\n",
    "            c.append(np.random.choice(max_class_counts))\n",
    "            class_dict[c[-1]]['count'] -= 1\n",
    "        class_partitions['class'].append(c)\n",
    "        class_partitions['prob'].append([class_dict[i]['prob'].pop() for i in c])\n",
    "    return class_partitions\n",
    "\n",
    "\n",
    "def gen_data_split(dataset, num_users, class_partitions):\n",
    "    \"\"\"\n",
    "    divide data indexes for each client based on class_partition\n",
    "    :param dataset: pytorch dataset object (train/val/test)\n",
    "    :param num_users: number of clients\n",
    "    :param class_partitions: proportion of classes per client\n",
    "    :return: dictionary mapping client to its indexes\n",
    "    \"\"\"\n",
    "    num_classes, num_samples, data_labels_list = get_num_classes_samples(dataset)\n",
    "\n",
    "    # -------------------------- #\n",
    "    # Create class index mapping #\n",
    "    # -------------------------- #\n",
    "    data_class_idx = {i: np.where(data_labels_list == i)[0] for i in range(num_classes)}\n",
    "\n",
    "    # --------- #\n",
    "    # Shuffling #\n",
    "    # --------- #\n",
    "    for data_idx in data_class_idx.values():\n",
    "        random.shuffle(data_idx)\n",
    "\n",
    "    # ------------------------------ #\n",
    "    # Assigning samples to each user #\n",
    "    # ------------------------------ #\n",
    "    user_data_idx = [[] for i in range(num_users)]\n",
    "    for usr_i in range(num_users):\n",
    "        for c, p in zip(class_partitions['class'][usr_i], class_partitions['prob'][usr_i]):\n",
    "            end_idx = int(num_samples[c] * p)\n",
    "            user_data_idx[usr_i].extend(data_class_idx[c][:end_idx])\n",
    "            data_class_idx[c] = data_class_idx[c][end_idx:]\n",
    "        if len(user_data_idx[usr_i])%2 == 1: user_data_idx[usr_i] = user_data_idx[usr_i][:-1]\n",
    "\n",
    "    return user_data_idx\n",
    "\n",
    "\n",
    "def gen_classes_id(num_users=10, num_classes_per_user=2, classes=10):\n",
    "    class_partitions = defaultdict(list)\n",
    "    class_counts = [list(range(classes)) for _ in range(num_classes_per_user)]\n",
    "    user_data_classes = []\n",
    "    for user in range(num_users):\n",
    "        classes_user = np.random.choice(class_counts[0], size=1)\n",
    "        class_counts[0].remove(classes_user[0])\n",
    "        tmp = class_counts[1].copy()\n",
    "        if classes_user[0] in tmp:tmp.remove(classes_user[0])\n",
    "        if tmp is None:\n",
    "            tmp=[user_data_classes[-1][0]]\n",
    "            user_data_classes[-1][0] = classes_user[0]\n",
    "        classes_user = np.append(classes_user, np.random.choice(tmp, size=1))\n",
    "        class_counts[1].remove(classes_user[1])\n",
    "        user_data_classes.append(classes_user)\n",
    "    for c in user_data_classes:\n",
    "        class_partitions['class'].append(c)\n",
    "        class_partitions['prob'].append([0.5, 0.5])\n",
    "    return class_partitions\n",
    "\n",
    "\n",
    "def gen_classes(num_users=10, num_classes_per_user=6, classes=10):\n",
    "    class_partitions = defaultdict(list)\n",
    "    class_counts = [list(range(classes)) for _ in range(num_classes_per_user)]\n",
    "    user_data_classes = []\n",
    "    for user in range(num_users):\n",
    "        user_data_classes.append(np.array([*range(user, user+num_classes_per_user)])%10)\n",
    "    for c in user_data_classes:\n",
    "        class_partitions['class'].append(c)\n",
    "        class_partitions['prob'].append([1/num_classes_per_user]*num_classes_per_user)\n",
    "    return class_partitions\n",
    "\n",
    "\n",
    "def gen_random_loaders(data_name, data_path, num_users, bz, num_classes_per_user, num_classes, preprocess=None):\n",
    "    \"\"\"\n",
    "    generates train/val/test loaders of each client\n",
    "    :param data_name: name of dataset, choose from [cifar10, cifar100]\n",
    "    :param data_path: root path for data dir\n",
    "    :param num_users: number of clients\n",
    "    :param bz: batch size\n",
    "    :param classes_per_user: number of classes assigned to each client\n",
    "    :return: train/val/test loaders of each client, list of pytorch dataloaders\n",
    "    \"\"\"\n",
    "    loader_params = {\"batch_size\": bz, \"shuffle\": False, \"pin_memory\": True, \"num_workers\": 0}\n",
    "    dataloaders = []\n",
    "    datasets = get_datasets(data_name, data_path, preprocess=preprocess)\n",
    "    cls_partitions = None\n",
    "    distribution = np.zeros((num_users, num_classes))\n",
    "    for i, d in enumerate(datasets):\n",
    "        if i == 0:\n",
    "            cls_partitions = gen_classes_per_node(d, num_users, num_classes_per_user)\n",
    "            print(\"\\n每个客户端的类别分布:\")\n",
    "            for index in range(num_users):\n",
    "                print(f\"客户端 {index + 1}:\")\n",
    "                for class_idx, prob in zip(cls_partitions['class'][index], cls_partitions['prob'][index]):\n",
    "                    print(f\"  类别 {class_idx}: 概率 {prob:.4f}\")\n",
    "                distribution[index][cls_partitions['class'][index]] = cls_partitions['prob'][index]\n",
    "\n",
    "            loader_params['shuffle'] = True\n",
    "        usr_subset_idx = gen_data_split(d, num_users, cls_partitions)\n",
    "\n",
    "        subsets = list(map(lambda x: torch.utils.data.Subset(d, x), usr_subset_idx))\n",
    "        dataloaders.append(list(map(lambda x: torch.utils.data.DataLoader(x, **loader_params), subsets)))\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7d10d-8880-4058-8c2a-3282b6f8613b",
   "metadata": {},
   "source": [
    "## 4.FedUser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d497ad-044e-437a-b3e6-cf9b606f0126",
   "metadata": {},
   "source": [
    "CDPUser 和 LDPUser\n",
    "\n",
    "这两个类代表了PrivateFL中的客户端。它们的主要特点是：\n",
    "\n",
    "- 包含个性化数据转换层（InputNorm），这是PrivateFL的核心创新。\n",
    "- 在训练过程中同时优化数据转换和模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55291a69-49df-4a36-aab4-68816692a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from secretflow import PYUObject, proxy\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torchmetrics\n",
    "import opacus\n",
    "from opacus.validators import ModuleValidator\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "import numpy as np\n",
    "import time\n",
    "# from modelUtil import *\n",
    "\n",
    "@proxy(PYUObject)\n",
    "class CDPUser:\n",
    "    def __init__(self, index, device, model, input_shape, n_classes, train_dataloader, epochs, max_norm=1.0, disc_lr=5e-3, flr = 1e-1):\n",
    "        print(f\"初始化 CDPUser 参数: index={index}, device={device}, model={model}\")\n",
    "        # print(f\"Available local models: {locals().keys()}\\n\")\n",
    "        # print(f\"Available globals models: {globals().keys()}\")\n",
    "        # print(f\"Requested model: {model}\")\n",
    "        \n",
    "        self.index = index\n",
    "        self.device = device\n",
    "        # if 'linear_model' in model:\n",
    "        #     if input_shape == 1024:\n",
    "        #         self.model = globals()[model](num_classes=n_classes, input_shape=input_shape, bn_stats=True)\n",
    "        #     else:\n",
    "        #         self.model = globals()[model](num_classes=n_classes, input_shape=input_shape, bn_stats=False)\n",
    "        # else:\n",
    "        #     self.model = globals()[model](num_classes=n_classes)\n",
    "\n",
    "        model_name = model.__name__ if isinstance(model, type) else model\n",
    "        if 'linear_model' in model_name:\n",
    "            if input_shape == 1024:\n",
    "                self.model = model(num_classes=n_classes, input_shape=input_shape, bn_stats=True)\n",
    "            else:\n",
    "                self.model = model(num_classes=n_classes, input_shape=input_shape, bn_stats=False)\n",
    "        else:\n",
    "            self.model = model(num_classes=n_classes)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.disc_lr = disc_lr\n",
    "        self.acc_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=n_classes)#************to(self.device)\n",
    "        self.max_norm= max_norm\n",
    "        self.epochs = epochs\n",
    "        self.flr = flr\n",
    "        self.agg = True\n",
    "        if \"IN\" in model_name:\n",
    "            self.optim = torch.optim.SGD([ # 转换层（self.model.norm）的参数使用了不同的学习率（self.flr），这允许个性化转换层有不同于模型其他部分的优化策略。\n",
    "                                            {'params': self.model.norm.parameters(), 'lr': self.flr},\n",
    "                                            {'params': [v for k, v in self.model.named_parameters() if \"norm\" not in k]}], lr=self.disc_lr)\n",
    "            self.agg = False\n",
    "        else:\n",
    "            self.optim = torch.optim.SGD(self.model.parameters(), self.disc_lr)\n",
    "        # self.optim = torch.optim.SGD(self.model.parameters(), self.disc_lr)\n",
    "\n",
    "    def train(self):\n",
    "        # self.model.to(self.device)#************\n",
    "        self.model.train()\n",
    "        loading = []\n",
    "        for epoch in range(self.epochs):\n",
    "            losses = []\n",
    "            for images, labels in self.train_dataloader:\n",
    "                images, labels = images, labels # ************.to(self.device)\n",
    "                loading.append(self.optim.zero_grad())\n",
    "                logits, preds = self.model(images)\n",
    "                loss = self.loss_fn(logits, labels)\n",
    "                loading.append(loss.backward())\n",
    "                loading.append(self.optim.step())\n",
    "                loading.append(self.acc_metric(preds, labels))\n",
    "                losses.append(loss.item())\n",
    "            sf.wait(loading)\n",
    "            logging.info(f\"Client: {self.index} ACC: {self.acc_metric.compute()}, Loss:{np.mean(losses)}\")\n",
    "            self.acc_metric.reset()\n",
    "            # self.model.to('cpu')\n",
    "        # print(f\"{self.index} finished at {time.strftime('%X')}\")\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        # self.model.to(self.device)#************\n",
    "        logging.warning(f\"Client {self.index} start evaluating\")\n",
    "        self.model.eval()\n",
    "        testing_corrects = 0\n",
    "        testing_sum = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                # images, labels = images, labels#************.to(self.device)\n",
    "                _, preds = self.model(images)\n",
    "                testing_corrects += torch.sum(torch.argmax(preds, dim=1) == labels)\n",
    "                testing_sum += len(labels)\n",
    "        return testing_corrects.cpu().detach().numpy(), testing_sum \n",
    "\n",
    "    def get_model_state_dict(self):\n",
    "        return self.model.state_dict()\n",
    "    # 不直接返回 state_dict，而是返回一个可以在 PYU 间传输的数据结构Python 字典\n",
    "    # def get_model_state_dict(self):\n",
    "    #     state_dict = self.model.state_dict()\n",
    "    #     return {k: v.cpu().detach().numpy() for k, v in state_dict.items()}\n",
    "\n",
    "    def set_model_state_dict(self, weights):\n",
    "        # 先将weights转换到当前设备\n",
    "        # weights = weights.to(self.device)\n",
    "        if self.agg == False:\n",
    "            for key, value in self.model.state_dict().items():\n",
    "                if 'norm' not in key and 'bn' not in key and 'downsample.1' not in key:\n",
    "                    self.model.state_dict()[key].data.copy_(weights[key])\n",
    "        else:\n",
    "            for key, value in self.model.state_dict().items():\n",
    "                if 'bn' not in key:\n",
    "                    self.model.state_dict()[key].data.copy_(weights[key])\n",
    "\n",
    "@proxy(PYUObject)\n",
    "class LDPUser(CDPUser):\n",
    "    def __init__(self, index, device, model, n_classes, input_shape, train_dataloader, epochs, rounds, target_epsilon, target_delta, sr, max_norm=2.0, disc_lr=5e-1, mp_bs = 3):\n",
    "        super().__init__(index, device, model, n_classes, input_shape, train_dataloader, epochs=epochs, max_norm=max_norm, disc_lr=disc_lr)\n",
    "        self.rounds = rounds\n",
    "        self.target_epsilon = target_epsilon\n",
    "        self.epsilon = 0\n",
    "        self.delta = target_delta\n",
    "        self.model = ModuleValidator.fix(self.model)\n",
    "        self.optim = torch.optim.SGD(self.model.parameters(), self.disc_lr)\n",
    "        self.sr = sr\n",
    "        self.make_local_private()\n",
    "        self.agg = True\n",
    "        self.mp_bs = mp_bs\n",
    "\n",
    "        model_name = model.__name__ if isinstance(model, type) else model\n",
    "        if \"IN\" in model_name:\n",
    "            self.agg = False\n",
    "\n",
    "    def make_local_private(self):\n",
    "        self.privacy_engine = opacus.PrivacyEngine()\n",
    "        self.model, self.optim, self.train_dataloader = self.privacy_engine.make_private_with_epsilon(module=self.model, optimizer=self.optim,\n",
    "                                                                                                      data_loader=self.train_dataloader, epochs=self.epochs*self.rounds*self.sr,\n",
    "                                                                                                      target_epsilon=self.target_epsilon, target_delta=self.delta,\n",
    "                                                                                                      max_grad_norm=self.max_norm)\n",
    "    def train(self):\n",
    "        # self.model = self.model.to(self.device)\n",
    "        self.model.train()\n",
    "        loading = []\n",
    "        for epoch in range(self.epochs):\n",
    "            with BatchMemoryManager(data_loader=self.train_dataloader, max_physical_batch_size=self.mp_bs, optimizer=self.optim) as batch_loader:\n",
    "                for images, labels in batch_loader:\n",
    "                    images, labels = images, labels#************.to(self.device)\n",
    "                    loading.append(self.optim.zero_grad())\n",
    "                    logits, preds = self.model(images)\n",
    "                    loss = self.loss_fn(logits, labels)\n",
    "                    loading.append(loss.backward())\n",
    "                    loading.append(self.optim.step())\n",
    "                    loading.append(self.acc_metric(preds, labels))\n",
    "        sf.wait(loading)\n",
    "        self.epsilon = self.privacy_engine.get_epsilon(self.delta)\n",
    "        logging.info(f\"Client: {self.index} ACC: {self.acc_metric.compute()}, episilon: {self.epsilon}\")\n",
    "        self.acc_metric.reset()\n",
    "        # self.model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f66b25-ce50-49f7-a683-8ba2044b4f0e",
   "metadata": {},
   "source": [
    "## 5.FedServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d791b40e-6304-4561-a5f2-a3d544ba0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import opacus\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "@proxy(PYUObject)\n",
    "class CDPServer:\n",
    "    def __init__(self, device, model, input_shape, n_classes, noise_multiplier=1, sample_clients=10, disc_lr=1):\n",
    "        print(f\"初始化 CDPServer 参数: device={device}, model={model}\")\n",
    "        model_name = model.__name__ if isinstance(model, type) else model\n",
    "        if 'linear_model' in model_name:\n",
    "            self.model = model(num_classes=n_classes, input_shape=input_shape)\n",
    "        else:\n",
    "            self.model = model(num_classes=n_classes)\n",
    "        self.disc_lr = disc_lr\n",
    "        self.device = device\n",
    "        self.sample_clients = sample_clients\n",
    "        self.noise_multiplier = noise_multiplier\n",
    "        self.trainable_names = [k for k, _ in self.model.named_parameters()]\n",
    "        self.agg = True\n",
    "        if \"IN\" in model_name:\n",
    "            self.agg = False\n",
    "\n",
    "    def get_median_norm(self, weights):\n",
    "        logging.warning(\"Calculating median norm\")\n",
    "        median_norm = OrderedDict()\n",
    "        for k, v in self.model.named_parameters():\n",
    "            norms = []\n",
    "            for i in range(len(weights)):\n",
    "                grad =  v.detach()-weights[i][k]\n",
    "                norms.append(grad.norm(2))\n",
    "            median_norm[k] = min(median(norms), 10)\n",
    "        # print(median_norm)\n",
    "        return median_norm\n",
    "\n",
    "    def get_model_state_dict(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def agg_updates(self, weights):\n",
    "        logging.warning(\"CDP Server Aggregating updates\")\n",
    "        with torch.no_grad():\n",
    "            norms = self.get_median_norm(weights)\n",
    "            if self.agg == False:\n",
    "                for k, v in self.get_model_state_dict().items():\n",
    "                    if 'bn' not in k and 'norm' not in k and 'downsample.1' not in k:\n",
    "                        sumed_grad = torch.zeros_like(v)\n",
    "                        for i in range(len(weights)):\n",
    "                            grad = weights[i][k]-v\n",
    "                            grad = grad*min(1, norms[k]/grad.norm(2))\n",
    "                            sumed_grad += grad\n",
    "                        sigma = norms[k]*self.noise_multiplier\n",
    "                        sumed_grad += torch.normal(0, sigma, v.shape)\n",
    "                        value = v + sumed_grad/self.sample_clients\n",
    "                        self.model.state_dict()[k].data.copy_(value.detach().clone())\n",
    "            else:\n",
    "                for k, v in self.get_model_state_dict().items():\n",
    "                    if 'bn' not in k:\n",
    "                        sumed_grad = torch.zeros_like(v)\n",
    "                        for i in range(len(weights)):\n",
    "                            grad = weights[i][k]-v\n",
    "                            grad = grad*min(1, norms[k]/grad.norm(2))\n",
    "                            sumed_grad += grad\n",
    "                        sigma = norms[k]*self.noise_multiplier\n",
    "                        sumed_grad += torch.normal(0, sigma, v.shape)\n",
    "                        value = v + sumed_grad/self.sample_clients\n",
    "                        self.model.state_dict()[k].data.copy_(value.detach().clone())\n",
    "\n",
    "@proxy(PYUObject)\n",
    "class LDPServer(CDPServer):\n",
    "    def __init__(self, device, model, n_classes, input_shape, noise_multiplier=1, sample_clients=10, disc_lr=1):\n",
    "        super().__init__(device, model, n_classes, input_shape, noise_multiplier, sample_clients, disc_lr)\n",
    "        self.model = ModuleValidator.fix(self.model)\n",
    "        self.privacy_engine = opacus.PrivacyEngine()\n",
    "        self.model = self.privacy_engine._prepare_model(self.model)\n",
    "        model_name = model.__name__ if isinstance(model, type) else model\n",
    "        self.agg = True\n",
    "        if \"IN\" in model_name:\n",
    "            self.agg = False\n",
    "\n",
    "    def agg_updates(self, weights):\n",
    "        logging.warning(\"LDP Server aggregating updates\")\n",
    "        with torch.no_grad():\n",
    "            if self.agg == False:\n",
    "                for k, v in self.get_model_state_dict().items():\n",
    "                    if 'bn' not in k and 'norm' not in k and 'downsample.1' not in k:\n",
    "                        sumed_grad = torch.zeros_like(v)\n",
    "                        for i in range(len(weights)):\n",
    "                            grad = weights[i][k]-v\n",
    "                            sumed_grad += grad\n",
    "                        value = v + sumed_grad/self.sample_clients\n",
    "                        self.model.state_dict()[k].data.copy_(value.detach().clone())\n",
    "            else:\n",
    "                for k, v in self.get_model_state_dict().items():\n",
    "                    if 'bn' not in k:\n",
    "                        sumed_grad = torch.zeros_like(v)\n",
    "                        for i in range(len(weights)):\n",
    "                            grad = weights[i][k]-v\n",
    "                            sumed_grad += grad\n",
    "                        value = v + sumed_grad/self.sample_clients\n",
    "                        self.model.state_dict()[k].data.copy_(value.detach().clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1bf751-0db2-4db0-87ca-0d2a2ac1193a",
   "metadata": {},
   "source": [
    "## 6.FedAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5234e90a-683a-4777-9e59-046c14e0962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 直接设置参数值\n",
    "args = type('Args', (), {\n",
    "    'data': 'mnist',\n",
    "    'nclient': 50,\n",
    "    'nclass': 10,\n",
    "    'ncpc': 2,\n",
    "    'model': 'mnist_fully_connected_IN',\n",
    "    'mode': 'CDP',\n",
    "    'round': 60,\n",
    "    'epsilon': 2,\n",
    "    'physical_bs': 64,\n",
    "    'sr': 1.0,\n",
    "    'lr': 5e-3,\n",
    "    'flr': 1e-2,\n",
    "    'E': 1\n",
    "})()\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "today = date.today().isoformat()\n",
    "DATA_NAME = args.data\n",
    "NUM_CLIENTS = args.nclient\n",
    "NUM_CLASSES = args.nclass\n",
    "NUM_CLASES_PER_CLIENT = args.ncpc\n",
    "MODEL = args.model\n",
    "MODE = args.mode\n",
    "EPOCHS = 1\n",
    "ROUNDS = args.round\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE_DIS = args.lr\n",
    "LEARNING_RATE_F = args.flr\n",
    "mp_bs = args.physical_bs\n",
    "target_epsilon = args.epsilon\n",
    "target_delta = 1e-3\n",
    "sample_rate = args.sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b845553f-cfa4-43d7-bde9-58968f1a21e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanglei/anaconda3/envs/privatefl_sf/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _posixsubprocess.fork_exec(\n",
      "2024-10-21 02:19:23,504\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m 初始化 CDPUser 参数: index=0, device=client_0, model=<class '__main__.mnist_fully_connected_IN'>\n",
      "\u001b[36m(ActorCDPUser pid=3026167)\u001b[0m \n",
      "\u001b[36m(ActorCDPUser pid=3027221)\u001b[0m 初始化 CDPUser 参数: index=19, device=client_19, model=<class '__main__.mnist_fully_connected_IN'>\n",
      "\u001b[36m(ActorCDPUser pid=3028421)\u001b[0m 初始化 CDPUser 参数: index=35, device=client_35, model=<class '__main__.mnist_fully_connected_IN'>\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m 初始化 CDPServer 参数: device=server, model=<class '__main__.mnist_fully_connected_IN'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m /home/zhanglei/anaconda3/envs/privatefl_sf/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "\u001b[36m(ActorCDPUser pid=3026261)\u001b[0m INFO:root:Client: 5 ACC: 0.5023659467697144, Loss:1.7611481130123139\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m WARNING:root:Client 0 start evaluating\n",
      "\u001b[36m(ActorCDPUser pid=3029415)\u001b[0m /home/zhanglei/anaconda3/envs/privatefl_sf/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029415)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m INFO:root:Client: 39 ACC: 0.4984227120876312, Loss:1.7636819422245025\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029163)\u001b[0m WARNING:root:Client 43 start evaluating\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028094)\u001b[0m INFO:root:Client: 31 ACC: 0.8081967234611511, Loss:0.7325190022587776\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027502)\u001b[0m WARNING:root:Client 23 start evaluating\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026261)\u001b[0m INFO:root:Client: 5 ACC: 0.8328076004981995, Loss:0.46938364803791044\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026261)\u001b[0m WARNING:root:Client 5 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m INFO:root:Client: 38 ACC: 0.8392568826675415, Loss:0.5137490957975388\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m INFO:root:Client: 39 ACC: 0.789432168006897, Loss:0.6936628542840481\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028492)\u001b[0m WARNING:root:Client 36 start evaluating\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m INFO:root:Client: 38 ACC: 0.8368335962295532, Loss:0.5849316488951445\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026879)\u001b[0m WARNING:root:Client 14 start evaluating\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026098)\u001b[0m INFO:root:Client: 3 ACC: 0.702296793460846, Loss:0.9520159231291877\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026038)\u001b[0m INFO:root:Client: 1 ACC: 0.8444790244102478, Loss:0.5771008531252543\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028987)\u001b[0m WARNING:root:Client 41 start evaluating\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026261)\u001b[0m INFO:root:Client: 5 ACC: 0.858832836151123, Loss:0.8669124782201834\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027433)\u001b[0m WARNING:root:Client 22 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m INFO:root:Client: 47 ACC: 0.7818335890769958, Loss:0.8339127341383382\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026167)\u001b[0m WARNING:root:Client 4 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029576)\u001b[0m WARNING:root:Client 48 start evaluating\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026673)\u001b[0m INFO:root:Client: 11 ACC: 0.7662671208381653, Loss:0.9040878164140802\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028020)\u001b[0m WARNING:root:Client 30 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026812)\u001b[0m INFO:root:Client: 13 ACC: 0.7902397513389587, Loss:0.7200765382302435\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026583)\u001b[0m WARNING:root:Client 10 start evaluating\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028094)\u001b[0m INFO:root:Client: 31 ACC: 0.8565573692321777, Loss:0.43724088445305825\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m INFO:root:Client: 47 ACC: 0.8081493973731995, Loss:0.5366216152906418\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m WARNING:root:Client 39 start evaluating\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027155)\u001b[0m INFO:root:Client: 18 ACC: 0.9082278609275818, Loss:0.2779625687748194\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027294)\u001b[0m WARNING:root:Client 20 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m INFO:root:Client: 38 ACC: 0.8877221345901489, Loss:0.3527982357889414\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026038)\u001b[0m WARNING:root:Client 1 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027294)\u001b[0m INFO:root:Client: 20 ACC: 0.9269051551818848, Loss:0.23027020834741138\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029415)\u001b[0m WARNING:root:Client 46 start evaluating\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027155)\u001b[0m INFO:root:Client: 18 ACC: 0.9485759735107422, Loss:0.1761498810723424\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027948)\u001b[0m WARNING:root:Client 29 start evaluating\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026673)\u001b[0m INFO:root:Client: 11 ACC: 0.9015411138534546, Loss:0.3013423783214469\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026583)\u001b[0m WARNING:root:Client 10 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028169)\u001b[0m INFO:root:Client: 32 ACC: 0.9214618802070618, Loss:0.24668847201835542\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029341)\u001b[0m INFO:root:Client: 45 ACC: 0.9597039222717285, Loss:0.156406458663313\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m WARNING:root:Client 39 start evaluating\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029253)\u001b[0m INFO:root:Client: 44 ACC: 0.9642857313156128, Loss:0.15541558751934453\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026261)\u001b[0m WARNING:root:Client 5 start evaluating\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027017)\u001b[0m WARNING:root:Client 16 start evaluating\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027728)\u001b[0m WARNING:root:Client 26 start evaluating\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028591)\u001b[0m WARNING:root:Client 37 start evaluating\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029576)\u001b[0m WARNING:root:Client 48 start evaluating\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026055)\u001b[0m INFO:root:Client: 2 ACC: 0.9099173545837402, Loss:0.2621061511729893\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027433)\u001b[0m WARNING:root:Client 22 start evaluating\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028345)\u001b[0m INFO:root:Client: 34 ACC: 0.9031690359115601, Loss:0.28918616970380145\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026098)\u001b[0m WARNING:root:Client 3 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m INFO:root:Client: 47 ACC: 0.921901524066925, Loss:0.2372104000104101\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027155)\u001b[0m INFO:root:Client: 18 ACC: 0.9731012582778931, Loss:0.108347244001925\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027948)\u001b[0m WARNING:root:Client 29 start evaluating\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m INFO:root:Client: 0 ACC: 0.9586846828460693, Loss:0.13494091010407397\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026583)\u001b[0m WARNING:root:Client 10 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m INFO:root:Client: 47 ACC: 0.9295415878295898, Loss:0.20871230018766304\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m INFO:root:Client: 39 ACC: 0.9794952869415283, Loss:0.10071913078427315\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m WARNING:root:Client 38 start evaluating\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028169)\u001b[0m INFO:root:Client: 32 ACC: 0.9657853841781616, Loss:0.11621784418821335\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027017)\u001b[0m WARNING:root:Client 16 start evaluating\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026673)\u001b[0m INFO:root:Client: 11 ACC: 0.9537671208381653, Loss:0.1670634977911648\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m WARNING:root:Client 0 start evaluating\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027948)\u001b[0m INFO:root:Client: 29 ACC: 0.960567831993103, Loss:0.15238253995776177\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029415)\u001b[0m WARNING:root:Client 46 start evaluating\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028259)\u001b[0m INFO:root:Client: 33 ACC: 0.9583333134651184, Loss:0.1517206983346688\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027879)\u001b[0m WARNING:root:Client 28 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028094)\u001b[0m INFO:root:Client: 31 ACC: 0.9606557488441467, Loss:0.15189700685441493\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026538)\u001b[0m WARNING:root:Client 9 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m INFO:root:Client: 0 ACC: 0.96205735206604, Loss:0.11208880182943846\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029341)\u001b[0m INFO:root:Client: 45 ACC: 0.9835526347160339, Loss:0.0779529674664924\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028591)\u001b[0m WARNING:root:Client 37 start evaluating\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m INFO:root:Client: 47 ACC: 0.9431239366531372, Loss:0.16791728178137227\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027221)\u001b[0m WARNING:root:Client 19 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m INFO:root:Client: 39 ACC: 0.9802839159965515, Loss:0.07375348582863808\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026038)\u001b[0m WARNING:root:Client 1 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029576)\u001b[0m WARNING:root:Client 48 start evaluating\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027360)\u001b[0m INFO:root:Client: 21 ACC: 0.9537190198898315, Loss:0.13765272929480202\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028020)\u001b[0m WARNING:root:Client 30 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m INFO:root:Client: 47 ACC: 0.9405772686004639, Loss:0.15978262691121353\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026673)\u001b[0m WARNING:root:Client 11 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026261)\u001b[0m INFO:root:Client: 5 ACC: 0.9810725450515747, Loss:0.07332886010408401\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029253)\u001b[0m INFO:root:Client: 44 ACC: 0.976190447807312, Loss:0.07356222091536772\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m WARNING:root:Client 39 start evaluating\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026098)\u001b[0m INFO:root:Client: 3 ACC: 0.9514134526252747, Loss:0.14462358545925882\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027360)\u001b[0m WARNING:root:Client 21 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028259)\u001b[0m INFO:root:Client: 33 ACC: 0.9591836929321289, Loss:0.12418325539482267\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026055)\u001b[0m WARNING:root:Client 2 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028094)\u001b[0m INFO:root:Client: 31 ACC: 0.9647541046142578, Loss:0.10463268086314201\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029072)\u001b[0m INFO:root:Client: 42 ACC: 0.8968803882598877, Loss:0.30944008968378367\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028094)\u001b[0m WARNING:root:Client 31 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m INFO:root:Client: 0 ACC: 0.9704890251159668, Loss:0.08899457125287306\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026951)\u001b[0m WARNING:root:Client 15 start evaluating\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029253)\u001b[0m INFO:root:Client: 44 ACC: 0.9795918464660645, Loss:0.0672989803317346\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m WARNING:root:Client 0 start evaluating\u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028259)\u001b[0m INFO:root:Client: 33 ACC: 0.9642857313156128, Loss:0.11351124197244644\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029415)\u001b[0m WARNING:root:Client 46 start evaluating\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026261)\u001b[0m INFO:root:Client: 5 ACC: 0.9818611741065979, Loss:0.06171724172309041\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027948)\u001b[0m WARNING:root:Client 29 start evaluating\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026098)\u001b[0m INFO:root:Client: 3 ACC: 0.9549469947814941, Loss:0.13401427533891466\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026583)\u001b[0m WARNING:root:Client 10 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028345)\u001b[0m INFO:root:Client: 34 ACC: 0.9366196990013123, Loss:0.16406383530961144\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028169)\u001b[0m INFO:root:Client: 32 ACC: 0.9782270789146423, Loss:0.0750646208013807\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028492)\u001b[0m WARNING:root:Client 36 start evaluating\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026038)\u001b[0m INFO:root:Client: 1 ACC: 0.9774494767189026, Loss:0.06817720803831305\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027155)\u001b[0m WARNING:root:Client 18 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m INFO:root:Client: 0 ACC: 0.9747048616409302, Loss:0.08079303173642409\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m WARNING:root:Client 0 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027948)\u001b[0m INFO:root:Client: 29 ACC: 0.9708201885223389, Loss:0.1047066854313016\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029415)\u001b[0m WARNING:root:Client 46 start evaluating\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027294)\u001b[0m INFO:root:Client: 20 ACC: 0.9774494767189026, Loss:0.06516626113582225\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027879)\u001b[0m WARNING:root:Client 28 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m INFO:root:Client: 38 ACC: 0.9765751361846924, Loss:0.07538491133600474\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026538)\u001b[0m WARNING:root:Client 9 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027221)\u001b[0m INFO:root:Client: 19 ACC: 0.9698046445846558, Loss:0.11245085174838702\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028169)\u001b[0m INFO:root:Client: 32 ACC: 0.9790046811103821, Loss:0.059935214485795724\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028492)\u001b[0m WARNING:root:Client 36 start evaluating\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028094)\u001b[0m INFO:root:Client: 31 ACC: 0.9704918265342712, Loss:0.08563791001215577\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027089)\u001b[0m WARNING:root:Client 17 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028169)\u001b[0m INFO:root:Client: 32 ACC: 0.9782270789146423, Loss:0.0554862054774449\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m WARNING:root:Client 0 start evaluating\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029415)\u001b[0m WARNING:root:Client 46 start evaluating\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027502)\u001b[0m INFO:root:Client: 23 ACC: 0.971731424331665, Loss:0.10371473948988649\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027800)\u001b[0m WARNING:root:Client 27 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m INFO:root:Client: 38 ACC: 0.9773828983306885, Loss:0.07409345861524344\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026469)\u001b[0m WARNING:root:Client 8 start evaluating\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028345)\u001b[0m INFO:root:Client: 34 ACC: 0.9480633735656738, Loss:0.14426518314414555\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m INFO:root:Client: 47 ACC: 0.9575551748275757, Loss:0.13006820549306117\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028421)\u001b[0m WARNING:root:Client 35 start evaluating\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026098)\u001b[0m INFO:root:Client: 3 ACC: 0.9611307382583618, Loss:0.11676387074920866\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3027089)\u001b[0m WARNING:root:Client 17 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m INFO:root:Client: 38 ACC: 0.9765751361846924, Loss:0.07166868643835186\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026015)\u001b[0m WARNING:root:Client 0 start evaluating\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028169)\u001b[0m INFO:root:Client: 32 ACC: 0.9805598855018616, Loss:0.05332714815934499\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m WARNING:root:Client 47 start evaluating\u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028094)\u001b[0m INFO:root:Client: 31 ACC: 0.9721311330795288, Loss:0.0783181066159159\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027948)\u001b[0m WARNING:root:Client 29 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026331)\u001b[0m INFO:root:Client: 6 ACC: 0.9706926941871643, Loss:0.09429807381497489\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026673)\u001b[0m WARNING:root:Client 11 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027294)\u001b[0m INFO:root:Client: 20 ACC: 0.9790046811103821, Loss:0.05659377721271345\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026373)\u001b[0m INFO:root:Client: 7 ACC: 0.9780033826828003, Loss:0.0647675123457846\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028808)\u001b[0m WARNING:root:Client 39 start evaluating\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026167)\u001b[0m INFO:root:Client: 4 ACC: 0.9516128897666931, Loss:0.12893321286690862\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027221)\u001b[0m WARNING:root:Client 19 start evaluating\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026167)\u001b[0m INFO:root:Client: 4 ACC: 0.9584040641784668, Loss:0.1290896366301336\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026038)\u001b[0m WARNING:root:Client 1 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029253)\u001b[0m INFO:root:Client: 44 ACC: 0.9846938848495483, Loss:0.04853993075850763\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3029504)\u001b[0m WARNING:root:Client 47 start evaluating\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028169)\u001b[0m INFO:root:Client: 32 ACC: 0.9836702942848206, Loss:0.05714743797268186\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3027948)\u001b[0m WARNING:root:Client 29 start evaluating\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3026469)\u001b[0m INFO:root:Client: 8 ACC: 0.9584745764732361, Loss:0.12719625509098956\u001b[32m [repeated 50x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026743)\u001b[0m WARNING:root:Client 12 start evaluating\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3026673)\u001b[0m INFO:root:Client: 11 ACC: 0.9743150472640991, Loss:0.07695926804291575\n",
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:CDP Server Aggregating updates\n",
      "\u001b[36m(ActorCDPServer pid=3029669)\u001b[0m WARNING:root:Calculating median norm\n",
      "\u001b[36m(ActorCDPUser pid=3028591)\u001b[0m INFO:root:Client: 37 ACC: 0.9673144817352295, Loss:0.10767790882123841\u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[36m(ActorCDPUser pid=3028698)\u001b[0m WARNING:root:Client 38 start evaluating\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m 初始化 CDPUser 参数: index=49, device=client_49, model=<class '__main__.mnist_fully_connected_IN'>\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# 初始化 secretflow\n",
    "sf.shutdown()\n",
    "sf.init(['server'] + [f'client_{i}' for i in range(args.nclient)], address='local', num_gpus=1)\n",
    "# 为服务器和每个客户端创建PYU（Party Unit）\n",
    "server_pyu = sf.PYU('server')\n",
    "client_pyus = [sf.PYU(f'client_{i}') for i in range(args.nclient)]\n",
    "\n",
    "os.makedirs(f'log/E{args.E}', exist_ok=True)\n",
    "user_param = {'disc_lr': LEARNING_RATE_DIS, 'epochs': EPOCHS}\n",
    "server_param = {}\n",
    "if MODE == \"LDP\":\n",
    "    user_obj = LDPUser\n",
    "    server_obj = LDPServer\n",
    "    user_param['rounds'] = ROUNDS\n",
    "    user_param['target_epsilon'] = target_epsilon\n",
    "    user_param['target_delta'] = target_delta\n",
    "    user_param['sr'] = sample_rate\n",
    "    user_param['mp_bs'] = mp_bs\n",
    "elif MODE == \"CDP\":\n",
    "    user_obj = CDPUser\n",
    "    server_obj = CDPServer\n",
    "    user_param['flr'] = LEARNING_RATE_F\n",
    "    server_param['noise_multiplier'] = opacus.accountants.utils.get_noise_multiplier(target_epsilon=target_epsilon,\n",
    "                                                                                 target_delta=target_delta, \n",
    "                                                                                 sample_rate=sample_rate, steps=ROUNDS)\n",
    "    # print(f\"noise_multipier: {server_param['noise_multiplier']}\")\n",
    "    server_param['sample_clients'] = sample_rate*NUM_CLIENTS\n",
    "else:\n",
    "    raise ValueError(\"Choose mode from [CDP, LDP]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd875a9e-a01c-4c34-bfda-a24fbbea9df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "每个客户端的类别分布:\n",
      "客户端 1:\n",
      "  类别 0: 概率 0.1000\n",
      "  类别 2: 概率 0.1000\n",
      "客户端 2:\n",
      "  类别 3: 概率 0.1000\n",
      "  类别 1: 概率 0.1000\n",
      "客户端 3:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 7: 概率 0.1000\n",
      "客户端 4:\n",
      "  类别 5: 概率 0.1000\n",
      "  类别 6: 概率 0.1000\n",
      "客户端 5:\n",
      "  类别 9: 概率 0.1000\n",
      "  类别 8: 概率 0.1000\n",
      "客户端 6:\n",
      "  类别 9: 概率 0.1000\n",
      "  类别 1: 概率 0.1000\n",
      "客户端 7:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 8:\n",
      "  类别 6: 概率 0.1000\n",
      "  类别 0: 概率 0.1000\n",
      "客户端 9:\n",
      "  类别 8: 概率 0.1000\n",
      "  类别 2: 概率 0.1000\n",
      "客户端 10:\n",
      "  类别 7: 概率 0.1000\n",
      "  类别 3: 概率 0.1000\n",
      "客户端 11:\n",
      "  类别 6: 概率 0.1000\n",
      "  类别 9: 概率 0.1000\n",
      "客户端 12:\n",
      "  类别 7: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 13:\n",
      "  类别 0: 概率 0.1000\n",
      "  类别 3: 概率 0.1000\n",
      "客户端 14:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 8: 概率 0.1000\n",
      "客户端 15:\n",
      "  类别 2: 概率 0.1000\n",
      "  类别 1: 概率 0.1000\n",
      "客户端 16:\n",
      "  类别 2: 概率 0.1000\n",
      "  类别 0: 概率 0.1000\n",
      "客户端 17:\n",
      "  类别 7: 概率 0.1000\n",
      "  类别 8: 概率 0.1000\n",
      "客户端 18:\n",
      "  类别 3: 概率 0.1000\n",
      "  类别 9: 概率 0.1000\n",
      "客户端 19:\n",
      "  类别 1: 概率 0.1000\n",
      "  类别 6: 概率 0.1000\n",
      "客户端 20:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 21:\n",
      "  类别 3: 概率 0.1000\n",
      "  类别 1: 概率 0.1000\n",
      "客户端 22:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 7: 概率 0.1000\n",
      "客户端 23:\n",
      "  类别 0: 概率 0.1000\n",
      "  类别 9: 概率 0.1000\n",
      "客户端 24:\n",
      "  类别 6: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 25:\n",
      "  类别 2: 概率 0.1000\n",
      "  类别 8: 概率 0.1000\n",
      "客户端 26:\n",
      "  类别 7: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 27:\n",
      "  类别 6: 概率 0.1000\n",
      "  类别 8: 概率 0.1000\n",
      "客户端 28:\n",
      "  类别 0: 概率 0.1000\n",
      "  类别 4: 概率 0.1000\n",
      "客户端 29:\n",
      "  类别 9: 概率 0.1000\n",
      "  类别 3: 概率 0.1000\n",
      "客户端 30:\n",
      "  类别 1: 概率 0.1000\n",
      "  类别 2: 概率 0.1000\n",
      "客户端 31:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 0: 概率 0.1000\n",
      "客户端 32:\n",
      "  类别 2: 概率 0.1000\n",
      "  类别 7: 概率 0.1000\n",
      "客户端 33:\n",
      "  类别 3: 概率 0.1000\n",
      "  类别 1: 概率 0.1000\n",
      "客户端 34:\n",
      "  类别 6: 概率 0.1000\n",
      "  类别 8: 概率 0.1000\n",
      "客户端 35:\n",
      "  类别 5: 概率 0.1000\n",
      "  类别 9: 概率 0.1000\n",
      "客户端 36:\n",
      "  类别 0: 概率 0.1000\n",
      "  类别 4: 概率 0.1000\n",
      "客户端 37:\n",
      "  类别 2: 概率 0.1000\n",
      "  类别 8: 概率 0.1000\n",
      "客户端 38:\n",
      "  类别 6: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 39:\n",
      "  类别 3: 概率 0.1000\n",
      "  类别 7: 概率 0.1000\n",
      "客户端 40:\n",
      "  类别 9: 概率 0.1000\n",
      "  类别 1: 概率 0.1000\n",
      "客户端 41:\n",
      "  类别 2: 概率 0.1000\n",
      "  类别 1: 概率 0.1000\n",
      "客户端 42:\n",
      "  类别 9: 概率 0.1000\n",
      "  类别 6: 概率 0.1000\n",
      "客户端 43:\n",
      "  类别 3: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 44:\n",
      "  类别 8: 概率 0.1000\n",
      "  类别 7: 概率 0.1000\n",
      "客户端 45:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 0: 概率 0.1000\n",
      "客户端 46:\n",
      "  类别 1: 概率 0.1000\n",
      "  类别 5: 概率 0.1000\n",
      "客户端 47:\n",
      "  类别 4: 概率 0.1000\n",
      "  类别 0: 概率 0.1000\n",
      "客户端 48:\n",
      "  类别 8: 概率 0.1000\n",
      "  类别 9: 概率 0.1000\n",
      "客户端 49:\n",
      "  类别 2: 概率 0.1000\n",
      "  类别 3: 概率 0.1000\n",
      "客户端 50:\n",
      "  类别 7: 概率 0.1000\n",
      "  类别 6: 概率 0.1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if DATA_NAME == 'purchase':\n",
    "    root = 'data/purchase/dataset_purchase'\n",
    "elif DATA_NAME == 'chmnist':\n",
    "    root = 'data/CHMNIST'\n",
    "else: root = '~/torch_data'\n",
    "\n",
    "train_dataloaders, test_dataloaders = gen_random_loaders(DATA_NAME, root, NUM_CLIENTS,\n",
    "                                                         BATCH_SIZE, NUM_CLASES_PER_CLIENT, NUM_CLASSES)\n",
    "\n",
    "# print(user_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b804f0ba-f644-411a-bba2-92f18ec2c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改：将device参数替换为相应的PYU,在secretflow中，计算设备由PYU表示\n",
    "users = [user_obj(i, client_pyus[i], device=client_pyus[i], model=globals()[MODEL], input_shape=None,  n_classes=NUM_CLASSES,  train_dataloader=train_dataloaders[i], **user_param) for i in range(NUM_CLIENTS)]\n",
    "server = server_obj(server_pyu, device=server_pyu, model=globals()[MODEL], input_shape=None, n_classes=NUM_CLASSES, **server_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b5ca1f-d9dc-4a41-b470-6c33db0c2851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1\n",
      "全局准确率: 0.0846\n",
      "Round: 2\n",
      "全局准确率: 0.1086\n",
      "Round: 3\n",
      "全局准确率: 0.1934\n",
      "Round: 4\n",
      "全局准确率: 0.1451\n",
      "Round: 5\n",
      "全局准确率: 0.1716\n",
      "Round: 6\n",
      "全局准确率: 0.1297\n",
      "Round: 7\n",
      "全局准确率: 0.1223\n",
      "Round: 8\n",
      "全局准确率: 0.2045\n",
      "Round: 9\n",
      "全局准确率: 0.2635\n",
      "Round: 10\n",
      "全局准确率: 0.3911\n",
      "Round: 11\n",
      "全局准确率: 0.5992\n",
      "Round: 12\n",
      "全局准确率: 0.6683\n",
      "Round: 13\n",
      "全局准确率: 0.8053\n",
      "Round: 14\n",
      "全局准确率: 0.8786\n",
      "Round: 15\n",
      "全局准确率: 0.9037\n",
      "Round: 16\n",
      "全局准确率: 0.9173\n",
      "Round: 17\n",
      "全局准确率: 0.9308\n",
      "Round: 18\n",
      "全局准确率: 0.9382\n",
      "Round: 19\n",
      "全局准确率: 0.9411\n",
      "Round: 20\n",
      "全局准确率: 0.9459\n",
      "Round: 21\n",
      "全局准确率: 0.9485\n",
      "Round: 22\n",
      "全局准确率: 0.9516\n",
      "Round: 23\n",
      "全局准确率: 0.9520\n",
      "Round: 24\n",
      "全局准确率: 0.9550\n",
      "Round: 25\n",
      "全局准确率: 0.9520\n",
      "Round: 26\n",
      "全局准确率: 0.9588\n",
      "Round: 27\n",
      "全局准确率: 0.9607\n",
      "Round: 28\n",
      "全局准确率: 0.9584\n",
      "Round: 29\n",
      "全局准确率: 0.9598\n",
      "Round: 30\n",
      "全局准确率: 0.9646\n",
      "Round: 31\n",
      "全局准确率: 0.9599\n",
      "Round: 32\n",
      "全局准确率: 0.9641\n",
      "Round: 33\n",
      "全局准确率: 0.9648\n",
      "Round: 34\n",
      "全局准确率: 0.9640\n",
      "Round: 35\n",
      "全局准确率: 0.9582\n",
      "Round: 36\n",
      "全局准确率: 0.9650\n",
      "Round: 37\n",
      "全局准确率: 0.9655\n",
      "Round: 38\n",
      "全局准确率: 0.9654\n",
      "Round: 39\n",
      "全局准确率: 0.9649\n",
      "Round: 40\n",
      "全局准确率: 0.9665\n",
      "Round: 41\n",
      "全局准确率: 0.9675\n",
      "Round: 42\n",
      "全局准确率: 0.9645\n",
      "Round: 43\n",
      "全局准确率: 0.9672\n",
      "Round: 44\n",
      "全局准确率: 0.9668\n",
      "Round: 45\n",
      "全局准确率: 0.9693\n",
      "Round: 46\n",
      "全局准确率: 0.9666\n",
      "Round: 47\n",
      "全局准确率: 0.9688\n",
      "Round: 48\n",
      "全局准确率: 0.9685\n",
      "Round: 49\n",
      "全局准确率: 0.9698\n",
      "Round: 50\n",
      "全局准确率: 0.9686\n",
      "Round: 51\n",
      "全局准确率: 0.9683\n",
      "Round: 52\n",
      "全局准确率: 0.9686\n",
      "Round: 53\n",
      "全局准确率: 0.9704\n",
      "Round: 54\n",
      "全局准确率: 0.9700\n",
      "Round: 55\n",
      "全局准确率: 0.9693\n",
      "Round: 56\n",
      "全局准确率: 0.9703\n",
      "Round: 57\n",
      "全局准确率: 0.9709\n",
      "Round: 58\n",
      "全局准确率: 0.9713\n",
      "Round: 59\n",
      "全局准确率: 0.9716\n",
      "Round: 60\n",
      "全局准确率: 0.9701\n",
      "Use time: 0.14h\n",
      "Best accuracy: 0.9716183574879227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ActorCDPUser pid=3029667)\u001b[0m WARNING:root:Client 49 start evaluating\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# def sf_train(clients, server, rounds):\n",
    "    # 原有代码: 为所有客户端设置初始模型\n",
    "server_state_dict  = server.get_model_state_dict()\n",
    "for i in range(NUM_CLIENTS):\n",
    "    # 使用 SecretFlow 的方法将服务器的状态字典传输到客户端\n",
    "    client_state_dict = server_state_dict.to(users[i].device)\n",
    "    users[i].set_model_state_dict(client_state_dict)\n",
    "best_acc = 0\n",
    "for round in range(ROUNDS):\n",
    "    random_index = np.random.choice(NUM_CLIENTS, int(sample_rate*NUM_CLIENTS), replace=False)\n",
    "    for index in random_index:users[index].train()\n",
    "    if MODE == \"LDP\":\n",
    "        weights_agg = agg_weights([users[index].get_model_state_dict() for index in random_index])\n",
    "        for i in range(NUM_CLIENTS):\n",
    "            users[i].set_model_state_dict(weights_agg)\n",
    "    else:\n",
    "        server.agg_updates([users[index].get_model_state_dict().to(server.device) for index in random_index])\n",
    "        server_state_dict = server.get_model_state_dict()\n",
    "        for i in range(NUM_CLIENTS):\n",
    "            client_state_dict = server_state_dict.to(users[i].device)\n",
    "            users[i].set_model_state_dict(client_state_dict)\n",
    "    print(f\"Round: {round+1}\")\n",
    "    acc = evaluate_global(users, test_dataloaders, range(NUM_CLIENTS))\n",
    "    # total_corrects, total_samples = evaluate_global(users, test_dataloaders, range(NUM_CLIENTS))\n",
    "    # acc = total_corrects / total_samples\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    if MODE == \"LDP\":\n",
    "        eps = max([user.epsilon for user in users])\n",
    "        print(f\"Epsilon: {eps}\")\n",
    "        if eps > target_epsilon:\n",
    "            break\n",
    "    # return best_acc\n",
    "\n",
    "# best_acc = sf_train(users, server, ROUNDS)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Use time: {:.2f}h\".format((end_time - start_time)/3600.0))\n",
    "print(f'Best accuracy: {best_acc}')\n",
    "results_df = pd.DataFrame(columns=[\"data\",\"num_client\",\"ncpc\",\"mode\",\"model\",\"epsilon\",\"accuracy\"])\n",
    "results_df = results_df._append(\n",
    "    {\"data\": DATA_NAME, \"num_client\": NUM_CLIENTS,\n",
    "     \"ncpc\": NUM_CLASES_PER_CLIENT, \"mode\":MODE,\n",
    "     \"model\": MODEL, \"epsilon\": target_epsilon, \"accuracy\": best_acc},\n",
    "    ignore_index=True)\n",
    "results_df.to_csv(f'log/E{args.E}/{DATA_NAME}_{NUM_CLIENTS}_{NUM_CLASES_PER_CLIENT}_{MODE}_{MODEL}_{target_epsilon}.csv', index=False)\n",
    "\n",
    "sf.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privatefl_sf",
   "language": "python",
   "name": "privatefl_sf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
